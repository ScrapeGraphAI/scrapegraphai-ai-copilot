[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using hugging face as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n\n\n\n## required environment variable in .env\n#HUGGINGFACEHUB_API_TOKEN\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the events, with the following fields: company_name, event_name, event_start_date, event_start_time, event_end_date, event_end_time, location, event_mode, event_category, third_party_redirect, no_of_days, time_in_hours, hosted_or_attending, refreshments_type,  registration_available, registration_link\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://www.hmhco.com/event\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using hugging face as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom typing import Dict\n\nfrom pydantic import BaseModel\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Project(BaseModel):\n    title: str\n    description: str\n\nclass Projects(BaseModel):\n    Projects: Dict[str, Project]\n\n## required environment variable in .env\n#HUGGINGFACEHUB_API_TOKEN\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    schema=Projects,\n    config=graph_config\n)\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on internet using hugging face as a provider?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using hugging face as a provider and given a schema?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using hugging face as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using hugging face as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using hugging face as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper from text\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using hugging face as a provider?",
        "answer": "import os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\nsource = \"\"\"\n    The Divine Comedy, Italian La Divina Commedia, original name La commedia, long narrative poem written in Italian \n    circa 1308/21 by Dante. It is usually held to be one of the world s great works of literature. \n    Divided into three major sections—Inferno, Purgatorio, and Paradiso—the narrative traces the journey of Dante \n    from darkness and error to the revelation of the divine light, culminating in the Beatific Vision of God. \n    Dante is guided by the Roman poet Virgil, who represents the epitome of human knowledge, from the dark wood \n    through the descending circles of the pit of Hell (Inferno). He then climbs the mountain of Purgatory, guided \n    by the Roman poet Statius, who represents the fulfilment of human knowledge, and is finally led by his lifelong love, \n    the Beatrice of his earlier poetry, through the celestial spheres of Paradise.\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=\"Summarize the text and find the main topics\",\n    source=source,\n    config=graph_config,\n)\nresult = pdf_scraper_graph.run()\n\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using hugging face as a provider?",
        "answer": "\"\"\"\nExample of custom graph using existing nodes\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_openai import OpenAIEmbeddings\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = OpenAI(graph_config[\"llm\"])\nembedder = OpenAIEmbeddings(api_key=llm_model.openai_api_key)\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True,\n        }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True,\n    }\n)\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True,\n    }\n)\nrag_node = RAGNode(\n    input=\"user_prompt & (parsed_doc | doc)\",\n    output=[\"relevant_chunks\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"embedder_model\": embedder,\n        \"verbose\": True,\n    }\n)\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True,\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        rag_node,\n        generate_answer_node,\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, rag_node),\n        (rag_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in hugging face using beautifoulsoup?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using ScriptCreatorGraph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating multiple scripts in hugging face using beautifoulsoup?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLs in hugging face?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperMultiGraph from XML documents\n\"\"\"\n\nimport os\nfrom scrapegraphai.graphs import XMLScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n# ************************************************\n# Create the XMLScraperMultiGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=[text, text],  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in hugging face?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperMultiGraph from CSV documents\n\"\"\"\n\nimport os\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\n\n\n# ************************************************\n# Create the CSVScraperMultiGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperMultiGraph(\n    prompt=\"List me all the last names\",\n    source=[str(text), str(text)],\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a single JSON in hugging face?",
        "answer": "\"\"\"\nModule for showing how PDFScraper multi works\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in hugging face?",
        "answer": "\"\"\"\nModule for showing how PDFScraper multi works\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n}\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    }
]