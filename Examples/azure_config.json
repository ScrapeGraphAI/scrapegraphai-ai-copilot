[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using azure as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\n\n# required environment variable in .env\n# AZURE_OPENAI_ENDPOINT\n# AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\n# MODEL_NAME\n# AZURE_OPENAI_API_KEY\n# OPENAI_API_TYPE\n# AZURE_OPENAI_API_VERSION\n# AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\nload_dotenv()\n\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"\"\"List me all the events, with the following fields: company_name, event_name, event_start_date, event_start_time, \n    event_end_date, event_end_time, location, event_mode, event_category, \n    third_party_redirect, no_of_days, \n    time_in_hours, hosted_or_attending, refreshments_type, \n    registration_available, registration_link\"\"\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://www.hmhco.com/event\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using azure as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper with schema\n\"\"\"\n\nimport os, json\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Project(BaseModel):\n    title: str = Field(description=\"The title of the project\")\n    description: str = Field(description=\"The description of the project\")\n\nclass Projects(BaseModel):\n    projects: List[Project]\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    schema=Projects,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on internet using azure as a provider?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me the best escursions near Trento\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using azure as a provider and given a schema?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Dish(BaseModel):\n    name: str = Field(description=\"The name of the dish\")\n    description: str = Field(description=\"The description of the dish\")\n\nclass Dishes(BaseModel):\n    dishes: List[Dish]\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config,\n    schema=Dishes\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using azure as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\nsmart_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using azure as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using azure as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper from text\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using azure as a provider?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using azure as a provider?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in azure using beautifoulsoup?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using ScriptCreatorGraph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating multiple scripts in azure using beautifoulsoup?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLs in azure?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperMultiGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the XMLScraperMultiGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=[text, text],  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in azure?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperMultiGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the CSVScraperMultiGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperMultiGraph(\n    prompt=\"List me all the last names\",\n    source=[str(text), str(text)],\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a single JSON in azure?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\nsmart_scraper_graph = JSONScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in azure?",
        "answer": "\"\"\"\nModule for showing how JSONScraperMultiGraph multi works\n\"\"\"\nimport os\nfrom dotenv import load_dotenv\nimport json\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\n\nload_dotenv()\n\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.environ[\"AZURE_OPENAI_KEY\"],\n        \"model\": \"azure/gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    }
]