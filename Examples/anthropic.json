[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using haiku (anthropic) as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\n\n# required environment variables in .env\n# ANTHROPIC_API_KEY\nload_dotenv()\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"\"\"Don't say anything else. Output JSON only. List me all the events, with the following fields: company_name, event_name, event_start_date, event_start_time, \n    event_end_date, event_end_time, location, event_mode, event_category, \n    third_party_redirect, no_of_days, \n    time_in_hours, hosted_or_attending, refreshments_type, \n    registration_available, registration_link\"\"\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://www.hmhco.com/event\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using haiku (anthropic) as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\n\n# required environment variables in .env\n# HUGGINGFACEHUB_API_TOKEN\n# ANTHROPIC_API_KEY\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nschema= \"\"\"\n    { \n    \"Projects\": [\n        \"Project #\": \n            { \n                \"title\": \"...\", \n                \"description\": \"...\", \n            }, \n        \"Project #\": \n            { \n                \"title\": \"...\", \n                \"description\": \"...\", \n            } \n        ] \n    } \n\"\"\"\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000},\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    # also accepts a string with the already downloaded HTML code\n    schema=schema,\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on internet using haiku (anthropic) as a provider?",
        "filename": ""
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using anthropic as a provider and given a schema?",
        "filename": "search_graph_schema_haiku.py"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple websites given a prompt using haiku (anthropic) as a provider?",
        "filename": ""
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using haiku (anthropic) as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using haiku (anthropic) as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\n# required environment variables in .env\n# HUGGINGFACEHUB_API_TOKEN\n# ANTHROPIC_API_KEY\nload_dotenv()\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using haiku (anthropic) as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper from text\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using haiku (anthropic) as a provider?",
        "answer": "import os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\nsource = \"\"\"\n    The Divine Comedy, Italian La Divina Commedia, original name La commedia, long narrative poem written in Italian \n    circa 1308/21 by Dante. It is usually held to be one of the world s great works of literature. \n    Divided into three major sections\u2014Inferno, Purgatorio, and Paradiso\u2014the narrative traces the journey of Dante \n    from darkness and error to the revelation of the divine light, culminating in the Beatific Vision of God. \n    Dante is guided by the Roman poet Virgil, who represents the epitome of human knowledge, from the dark wood \n    through the descending circles of the pit of Hell (Inferno). He then climbs the mountain of Purgatory, guided \n    by the Roman poet Statius, who represents the fulfilment of human knowledge, and is finally led by his lifelong love, \n    the Beatrice of his earlier poetry, through the celestial spheres of Paradise.\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=\"Summarize the text and find the main topics\",\n    source=source,\n    config=graph_config,\n)\nresult = pdf_scraper_graph.run()\n\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using haiku (anthropic) as a provider?",
        "answer": "\"\"\"\nExample of custom graph using existing nodes\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_openai import OpenAIEmbeddings\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = OpenAI(graph_config[\"llm\"])\nembedder = OpenAIEmbeddings(api_key=llm_model.openai_api_key)\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True,\n        }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True,\n    }\n)\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True,\n    }\n)\nrag_node = RAGNode(\n    input=\"user_prompt & (parsed_doc | doc)\",\n    output=[\"relevant_chunks\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"embedder_model\": embedder,\n        \"verbose\": True,\n    }\n)\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True,\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        rag_node,\n        generate_answer_node,\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, rag_node),\n        (rag_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in haiku (anthropic) using beautifoulsoup?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using ScriptCreatorGraph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n        \"model\": \"claude-3-haiku-20240307\",\n        \"max_tokens\": 4000\n        },\n}\n\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating multiple scripts in haiku (anthropic) using beautifoulsoup?",
        "filename": ""
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLs in haiku (anthropic)?",
        "filename": "xml_scraper_graph_multi_haiku.py"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in haiku (anthropic)?",
        "filename": "csv_scraper_graph_multi_haiku.py"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a single JSON in haiku (anthropic)?",
        "filename": "json_scraper_multi_haiku.py"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in haiku (anthropic)?",
        "filename": "json_scraper_multi_haiku.py"
    }
]