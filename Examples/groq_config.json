[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using groq as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using groq as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper with schema\n\"\"\"\n\nimport os, json\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Project(BaseModel):\n    title: str = Field(description=\"The title of the project\")\n    description: str = Field(description=\"The description of the project\")\n\nclass Projects(BaseModel):\n    projects: List[Project]\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    schema=Projects,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on internet using groq as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\nsearch_graph = SearchGraph(\n    prompt=\"List me the best escursions near Trento\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using groq as a provider and given a schema?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Dish(BaseModel):\n    name: str = Field(description=\"The name of the dish\")\n    description: str = Field(description=\"The description of the dish\")\n\nclass Dishes(BaseModel):\n    dishes: List[Dish]\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config,\n    schema=Dishes\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using groq as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using groq as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n}\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using groq as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper from text\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using groq as a provider?",
        "answer": "\"\"\"\nExample of pdf_scraper_graph \n\"\"\"\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n}\n\n\nsource = \"\"\"\n    The Divine Comedy, Italian La Divina Commedia, original name La commedia, long narrative poem written in Italian \n    circa 1308/21 by Dante. It is usually held to be one of the world s great works of literature. \n    Divided into three major sections—Inferno, Purgatorio, and Paradiso—the narrative traces the journey of Dante \n    from darkness and error to the revelation of the divine light, culminating in the Beatific Vision of God. \n    Dante is guided by the Roman poet Virgil, who represents the epitome of human knowledge, from the dark wood \n    through the descending circles of the pit of Hell (Inferno). He then climbs the mountain of Purgatory, guided \n    by the Roman poet Statius, who represents the fulfilment of human knowledge, and is finally led by his lifelong love, \n    the Beatrice of his earlier poetry, through the celestial spheres of Paradise.\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=\"Summarize the text and find the main topics\",\n    source=source,\n    config=graph_config,\n)\nresult = pdf_scraper_graph.run()\n\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using groq as a provider?",
        "answer": "\"\"\"\nExample of custom graph using existing nodes\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = ChatOpenAI(graph_config[\"llm\"])\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True,\n        }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True,\n    }\n)\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True,\n    }\n)\n\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True,\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        generate_answer_node,\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in groq using beautifoulsoup?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using ScriptCreatorGraph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"library\": \"beautifulsoup\"\n}\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating multiple scripts in groq using beautifoulsoup?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLs in groq?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperMultiGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n\n# ************************************************\n# Create the XMLScraperMultiGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=[text, text],  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in groq?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperMultiGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n# ************************************************\n# Create the CSVScraperMultiGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperMultiGraph(\n    prompt=\"List me all the last names\",\n    source=[str(text), str(text)],\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a single JSON in groq?",
        "answer": "\"\"\"\nModule for showing how JSONScraperMultiGraph multi works\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\n\nload_dotenv()\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"library\": \"beautifulsoup\"\n}\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in groq?",
        "answer": "\"\"\"\nModule for showing how JSONScraperMultiGraph multi works\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\n\nload_dotenv()\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"library\": \"beautifulsoup\"\n}\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    }
]