[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper\n\"\"\"\n\nimport os, json\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me what does the company do, the name and a contact email.\",\n    source=\"https://scrapegraphai.com/\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(json.dumps(result, indent=4))\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper with schema\n\"\"\"\n\nimport os, json\nfrom typing import List\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom scrapegraphai.graphs import SmartScraperGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Project(BaseModel):\n    title: str = Field(description=\"The title of the project\")\n    description: str = Field(description=\"The description of the project\")\n\nclass Projects(BaseModel):\n    projects: List[Project]\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\":openai_key,\n        \"model\": \"gpt-4o\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    schema=Projects,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and seaching on internet using openai as a provider?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"max_results\": 2,\n    \"verbose\": True,\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using openai as a provider and given a schema?",
        "answer": "\"\"\"\nExample of Search Graph\n\"\"\"\n\nimport os\nfrom typing import List\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel, Field\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nclass Dish(BaseModel):\n    name: str = Field(description=\"The name of the dish\")\n    description: str = Field(description=\"The description of the dish\")\n\nclass Dishes(BaseModel):\n    dishes: List[Dish]\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"max_results\": 2,\n    \"verbose\": True,\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config,\n    schema=Dishes\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using openai as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n    \"verbose\":False,\n}\n\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using openai as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SmartScraper from text\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using openai as a provider?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using openai as a provider?",
        "answer": "\"\"\"\nExample of custom graph using existing nodes\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_openai import OpenAIEmbeddings\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\ngraph_config = {\n     \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = OpenAI(graph_config[\"llm\"])\nembedder = OpenAIEmbeddings(api_key=llm_model.openai_api_key)\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True,\n        }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True,\n    }\n)\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True,\n    }\n)\nrag_node = RAGNode(\n    input=\"user_prompt & (parsed_doc | doc)\",\n    output=[\"relevant_chunks\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"embedder_model\": embedder,\n        \"verbose\": True,\n    }\n)\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True,\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        rag_node,\n        generate_answer_node,\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, rag_node),\n        (rag_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and seaching on internet using openai as a provider and using the omniscraper?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in openai?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating multiple scripts in haiku (anthopic) using beautifoulsoup?"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLS in openai?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using XMLScraperMultiGraph from XML documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\":openai_key,\n        \"model\": \"gpt-4o\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n# ************************************************\n# Create the XMLScraperMultiGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=[text, text],  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in openai ?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using CSVScraperMultiGraph from CSV documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n     \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n}\n\n# ************************************************\n# Create the CSVScraperMultiGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperMultiGraph(\n    prompt=\"List me all the last names\",\n    source=[str(text), str(text)],\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a single JSON in openai?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using JSONScraperGraph from JSON documents\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the JSON file\n# ************************************************\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n}\n\n# ************************************************\n# Create the JSONScraperGraph instance and run it\n# ************************************************\n\njson_scraper_graph = JSONScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = json_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = json_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in openai (anthopic)?",
        "answer": "\"\"\"\nModule for showing how PDFScraper multi works\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\n\nload_dotenv()\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    }\n}\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt= \"List me all the authors, title and genres of the books\",\n    source= sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for generating an audio file from the scraped content using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using SpeechSummaryGraph\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SpeechGraph\nfrom scrapegraphai.utils import prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Define audio output path\n# ************************************************\n\nFILE_NAME = \"website_summary.mp3\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\noutput_path = os.path.join(curr_dir, FILE_NAME)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n        \"temperature\": 0.7,\n    },\n    \"tts_model\": {\n        \"api_key\": openai_key,\n        \"model\": \"tts-1\",\n        \"voice\": \"alloy\"\n    },\n    \"output_path\": output_path,\n}\n\n# ************************************************\n# Create the SpeechGraph instance and run it\n# ************************************************\n\nspeech_graph = SpeechGraph(\n    prompt=\"Make a detailed audio summary of the projects.\",\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config,\n)\n\nresult = speech_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = speech_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a website extracting textual content and describing images given a user prompt and a URL using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using OmniScraper\n\"\"\"\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import OmniScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n    \"verbose\": True,\n    \"headless\": True,\n    \"max_images\": 5\n}\n\n# ************************************************\n# Create the OmniScraperGraph instance and run it\n# ************************************************\n\nomni_scraper_graph = OmniScraperGraph(\n    prompt=\"List me all the projects with their titles and image links and descriptions.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config\n)\n\nresult = omni_scraper_graph.run()\nprint(json.dumps(result, indent=2))\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = omni_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a website extracting textual content and describing images given a user prompt and a list of URLs using openai as a provider?",
        "answer": "\"\"\" \nBasic example of scraping pipeline using OmniScraper\n\"\"\"\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import OmniScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4o\",\n    },\n    \"verbose\": True,\n    \"headless\": True,\n    \"max_images\": 5\n}\n\n# ************************************************\n# Create the OmniScraperGraph instance and run it\n# ************************************************\n\nomni_scraper_graph = OmniScraperGraph(\n    prompt=\"List me all the projects with their titles and image links and descriptions.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config\n)\n\nresult = omni_scraper_graph.run()\nprint(json.dumps(result, indent=2))\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = omni_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a website extracting textual content and describing images given only a user prompt and making a search on the internet using openai as a provider?"
    }
]