[
    {
        "prompt": "how is get_probable_tags_node implemented in Scrapegraphai?",
        "answer": "\"\"\"\nGetProbableTagsNode Module\n\"\"\"\nfrom typing import List, Optional\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\nfrom langchain.prompts import PromptTemplate\nfrom ..utils.logging import get_logger\nfrom .base_node import BaseNode\n\n\nclass GetProbableTagsNode(BaseNode):\n    \"\"\"\n    A node that utilizes a language model to identify probable HTML tags within a document that\n    are likely to contain the information relevant to a user's query. This node generates a prompt\n    describing the task, submits it to the language model, and processes the output to produce a\n    list of probable tags.\n\n    Attributes:\n        llm_model: An instance of the language model client used for tag predictions.\n\n    Args:\n        input (str): Boolean expression defining the input keys needed from the state.\n        output (List[str]): List of output keys to be updated in the state.\n        model_config (dict): Additional configuration for the language model.\n        node_name (str): The unique identifier name for the node, defaulting to \"GetProbableTags\".\n    \"\"\"\n\n    def __init__(\n        self,\n        input: str,\n        output: List[str],\n        node_config: dict,\n        node_name: str = \"GetProbableTags\",\n    ):\n        super().__init__(node_name, \"node\", input, output, 2, node_config)\n\n        self.llm_model = node_config[\"llm_model\"]\n        self.verbose = (\n            False if node_config is None else node_config.get(\"verbose\", False)\n        )\n\n    def execute(self, state: dict) -> dict:\n        \"\"\"\n        Generates a list of probable HTML tags based on the user's input and updates the state\n        with this list. The method constructs a prompt for the language model, submits it, and\n        parses the output to identify probable tags.\n\n        Args:\n            state (dict): The current state of the graph. The input keys will be used to fetch the\n                            correct data types from the state.\n\n        Returns:\n            dict: The updated state with the input key containing a list of probable HTML tags.\n\n        Raises:\n            KeyError: If input keys are not found in the state, indicating that the\n                      necessary information for generating tag predictions is missing.\n        \"\"\"\n\n        self.logger.info(f\"--- Executing {self.node_name} Node ---\")\n\n        # Interpret input keys based on the provided input expression\n        input_keys = self.get_input_keys(state)\n\n        # Fetching data from the state based on the input keys\n        input_data = [state[key] for key in input_keys]\n\n        user_prompt = input_data[0]\n        url = input_data[1]\n\n        output_parser = CommaSeparatedListOutputParser()\n        format_instructions = output_parser.get_format_instructions()\n\n        template = \"\"\"\n        PROMPT:\n        You are a website scraper that knows all the types of html tags.\n        You are now asked to list all the html tags where you think you can find the information of the asked question.\\n \n        INSTRUCTIONS: {format_instructions} \\n  \n        WEBPAGE: The webpage is: {webpage} \\n \n        QUESTION: The asked question is the following: {question}\n        \"\"\"\n\n        tag_prompt = PromptTemplate(\n            template=template,\n            input_variables=[\"question\"],\n            partial_variables={\n                \"format_instructions\": format_instructions,\n                \"webpage\": url,\n            },\n        )\n\n        # Execute the chain to get probable tags\n        tag_answer = tag_prompt | self.llm_model | output_parser\n        probable_tags = tag_answer.invoke({\"question\": user_prompt})\n\n        # Update the dictionary with probable tags\n        state.update({self.output[0]: probable_tags})\n        return state\n"
    }
]