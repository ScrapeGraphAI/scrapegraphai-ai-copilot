[
    {
        "prompt": "how is merge_generated_scripts implemented in Scrapegraphai?",
        "answer": "\"\"\"\nMergeAnswersNode Module\n\"\"\"\n\n# Imports from standard library\nfrom typing import List, Optional\nfrom tqdm import tqdm\n\n# Imports from Langchain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser, StrOutputParser\nfrom tqdm import tqdm\n\nfrom ..utils.logging import get_logger\n\n# Imports from the library\nfrom .base_node import BaseNode\n\n\nclass MergeGeneratedScriptsNode(BaseNode):\n    \"\"\"\n    A node responsible for merging scripts generated.\n    Attributes:\n        llm_model: An instance of a language model client, configured for generating answers.\n        verbose (bool): A flag indicating whether to show print statements during execution.\n    Args:\n        input (str): Boolean expression defining the input keys needed from the state.\n        output (List[str]): List of output keys to be updated in the state.\n        node_config (dict): Additional configuration for the node.\n        node_name (str): The unique identifier name for the node, defaulting to \"GenerateAnswer\".\n    \"\"\"\n\n    def __init__(\n        self,\n        input: str,\n        output: List[str],\n        node_config: Optional[dict] = None,\n        node_name: str = \"MergeGeneratedScripts\",\n    ):\n        super().__init__(node_name, \"node\", input, output, 2, node_config)\n\n        self.llm_model = node_config[\"llm_model\"]\n        self.verbose = (\n            False if node_config is None else node_config.get(\"verbose\", False)\n        )\n\n    def execute(self, state: dict) -> dict:\n        \"\"\"\n        Executes the node's logic to merge the answers from multiple graph instances into a\n        single answer.\n        Args:\n            state (dict): The current state of the graph. The input keys will be used\n                            to fetch the correct data from the state.\n        Returns:\n            dict: The updated state with the output key containing the generated answer.\n        Raises:\n            KeyError: If the input keys are not found in the state, indicating\n                      that the necessary information for generating an answer is missing.\n        \"\"\"\n\n        self.logger.info(f\"--- Executing {self.node_name} Node ---\")\n\n        # Interpret input keys based on the provided input expression\n        input_keys = self.get_input_keys(state)\n\n        # Fetching data from the state based on the input keys\n        input_data = [state[key] for key in input_keys]\n\n        user_prompt = input_data[0]\n        scripts = input_data[1]\n\n        # merge the scripts in one string\n        scripts_str = \"\"\n        for i, script in enumerate(scripts):\n            scripts_str += \"-----------------------------------\\n\"\n            scripts_str += f\"SCRIPT URL {i+1}\\n\"\n            scripts_str += \"-----------------------------------\\n\"\n            scripts_str += script\n\n        # TODO: should we pass the schema to the output parser even if the scripts already have it implemented?\n\n        # schema to be used for output parsing\n        # if self.node_config.get(\"schema\", None) is not None:\n        #     output_schema = JsonOutputParser(pydantic_object=self.node_config[\"schema\"])\n        # else:\n        #     output_schema = JsonOutputParser()\n\n        # format_instructions = output_schema.get_format_instructions()\n\n        template_merge = \"\"\"\n        You are a python expert in web scraping and you have just generated multiple scripts to scrape different URLs.\\n\n        The scripts are generated based on a user question and the content of the websites.\\n\n        You need to create one single script that merges the scripts generated for each URL.\\n\n        The scraped contents are in a JSON format and you need to merge them based on the context and providing a correct JSON structure.\\n\n        The output should be just in python code without any comment and should implement the main function.\\n\n        The python script, when executed, should format the extracted information sticking to the user question and scripts output format.\\n\n        USER PROMPT: {user_prompt}\\n\n        SCRIPTS:\\n\n        {scripts}\n        \"\"\"\n\n        prompt_template = PromptTemplate(\n            template=template_merge,\n            input_variables=[\"user_prompt\"],\n            partial_variables={\n                \"scripts\": scripts_str,\n            },\n        )\n\n        merge_chain = prompt_template | self.llm_model | StrOutputParser()\n        answer = merge_chain.invoke({\"user_prompt\": user_prompt})\n\n        # Update the state with the generated answer\n        state.update({self.output[0]: answer})\n        return state"
    }
]